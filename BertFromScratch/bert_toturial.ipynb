{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入用于处理的库：\n",
    "1. 导入用于张量计算的pandas库\n",
    "2. 从transformers库中导入BERT模型和BERT分词器\n",
    "3. 导入用于构建神经网络的nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:15:44.528414800Z",
     "start_time": "2024-04-11T07:15:40.917536Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\cail\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch.nn as nn\n",
    "# pip install transformers -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "# pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从HuggingFace上下载预训练模型bert-base-chinese，将其地址存于model_name备用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:16:02.754547900Z",
     "start_time": "2024-04-11T07:16:02.744547800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = '../PretrainedModels/bert-base-chinese'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化一个分词器，命名为tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:16:03.390212600Z",
     "start_time": "2024-04-11T07:16:03.343341300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\cail\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的输入是一个列表，里面有两个文本，我们将input作为分词器的一个参数  \n",
    "\n",
    "分词器的参数除了input外，还有下面这些：\n",
    "1. padding：这里设置为True，填补分词结果中的空白处，使得分词结果的形状符合计算要求\n",
    "2. max_length：用于分词的单个序列的最大值\n",
    "3. truncation：设置为True后，如果输入序列的长度超过最大值，就会被截断\n",
    "4. return_tensors：设置为pt，分词后得到的张量类型为PyTorch Tensors\n",
    "\n",
    "input的分词结果保存在tokenize_input中，其为一个字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:16:54.672728200Z",
     "start_time": "2024-04-11T07:16:54.664728Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = ['根据权利书要求1所述的不锈钢复合桥面板焊接质量无损检测方法，其特征在于：包括：1）制定不锈钢复合桥面板焊接质量无损检测专项方案；2）采用一次直射波',\n",
    "'本发明是一种浮动平衡式盘配流径向柱塞泵，特别适用于需要高可靠性、高压力、大流量、低噪声、平稳长寿命的场合。其旨在保证高可靠性、减小噪声，提高使用寿命。']\n",
    "\n",
    "tokenize_input = tokenizer(input, padding=True,max_length=128, truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分词结果是一个字典，包括下面内容：\n",
    "1. input_ids：一个张量tensor，和上面的input对应，每个文本是一个一维张量，由于有两个文本，因此整体是一个二维的，张量中的每一个数字都代表文本中的一个字或符号的词向量id，注意到每个一维张量有意义的部分的开头都是101，结尾都是102，是因为101是代表接下来内容需要池化的标记[CLS]，102是用于分割句子或者代表文本片段结束的标记[SEP]，0就是填充进去的[PAD]\n",
    "2. token_type_ids：用于区分句子，不同的数字分属于不同的句子\n",
    "3. attention_mask：在注意力机制中需要进行掩盖的有意义的内容标记为1，pad标记为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-11T07:16:55.132469900Z",
     "start_time": "2024-04-11T07:16:55.097711200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 3418, 2945, 3326, 1164,  741, 6206, 3724,  122, 2792, 6835, 4638,\n",
       "          679, 7224, 7167, 1908, 1394, 3441, 7481, 3352, 4184, 2970, 6574, 7030,\n",
       "         3187, 2938, 3466, 3844, 3175, 3791, 8024, 1071, 4294, 2519, 1762,  754,\n",
       "         8038, 1259, 2886, 8038,  122, 8021, 1169, 2137,  679, 7224, 7167, 1908,\n",
       "         1394, 3441, 7481, 3352, 4184, 2970, 6574, 7030, 3187, 2938, 3466, 3844,\n",
       "          683, 7555, 3175, 3428, 8039,  123, 8021, 7023, 4500,  671, 3613, 4684,\n",
       "         2198, 3797,  102,    0,    0],\n",
       "        [ 101, 3315, 1355, 3209, 3221,  671, 4905, 3859, 1220, 2398, 6130, 2466,\n",
       "         4669, 6981, 3837, 2520, 1403, 3393, 1853, 3808, 8024, 4294, 1166, 6844,\n",
       "         4500,  754, 7444, 6206, 7770, 1377, 7479, 2595,  510, 7770, 1327, 1213,\n",
       "          510, 1920, 3837, 7030,  510,  856, 1692, 1898,  510, 2398, 4937, 7270,\n",
       "         2195, 1462, 4638, 1767, 1394,  511, 1071, 3192, 1762,  924, 6395, 7770,\n",
       "         1377, 7479, 2595,  510, 1121, 2207, 1692, 1898, 8024, 2990, 7770,  886,\n",
       "         4500, 2195, 1462,  511,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实例化一个BERT模型，命名为model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:03:36.432119Z",
     "start_time": "2023-12-26T21:03:35.410178Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\cail\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model(input_ids = tokenize_input['input_ids'],token_type_ids = tokenize_input['token_type_ids'],attention_mask = tokenize_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:03:38.441000Z",
     "start_time": "2023-12-26T21:03:37.938775Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = model(**tokenize_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:09:27.520735Z",
     "start_time": "2023-12-26T21:09:27.516575Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:09:27.826930Z",
     "start_time": "2023-12-26T21:09:27.821862Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 77, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:11:56.277404Z",
     "start_time": "2023-12-26T21:11:56.273768Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = out[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:11:56.723314Z",
     "start_time": "2023-12-26T21:11:56.722097Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(768,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:11:57.052205Z",
     "start_time": "2023-12-26T21:11:57.049591Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = linear1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-26T21:11:57.307546Z",
     "start_time": "2023-12-26T21:11:57.303672Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
